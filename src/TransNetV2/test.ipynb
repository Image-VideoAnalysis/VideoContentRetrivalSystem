{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "086a53a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /Users/marco/Desktop/Università/Esami/I. and V.A. with D.L./VisualContentAnalysis/VCA/lib/python3.11/site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /Users/marco/Desktop/Università/Esami/I. and V.A. with D.L./VisualContentAnalysis/VCA/lib/python3.11/site-packages (from opencv-python) (2.2.6)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: Pillow in /Users/marco/Desktop/Università/Esami/I. and V.A. with D.L./VisualContentAnalysis/VCA/lib/python3.11/site-packages (11.2.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install opencv-python\n",
    "%pip install Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c6b1128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import ffmpeg\n",
    "from transnet import TransNetV2\n",
    "from inference import predict_video\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from PIL import Image, ImageTk\n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "\n",
    "model = TransNetV2()\n",
    "state_dict = torch.load(\"transnetv2-pytorch-weights.pth\")\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d50ff4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying for ../../Test_dataset/00112.mp4\n",
      "[TransNetV2] Processing video frames 7676/7676Detected scenes: [[   0   71]\n",
      " [  73  134]\n",
      " [ 135  217]\n",
      " [ 218  302]\n",
      " [ 303  366]\n",
      " [ 367  460]\n",
      " [ 461  500]\n",
      " [ 501  533]\n",
      " [ 534  567]\n",
      " [ 568  616]\n",
      " [ 617  665]\n",
      " [ 666  698]\n",
      " [ 699  765]\n",
      " [ 766  795]\n",
      " [ 796  831]\n",
      " [ 832  865]\n",
      " [ 866  897]\n",
      " [ 898  934]\n",
      " [ 935  983]\n",
      " [ 984 1028]\n",
      " [1029 1126]\n",
      " [1127 1157]\n",
      " [1158 1195]\n",
      " [1196 1232]\n",
      " [1233 1263]\n",
      " [1264 1288]\n",
      " [1289 1468]\n",
      " [1469 1492]\n",
      " [1493 1528]\n",
      " [1529 1560]\n",
      " [1561 1630]\n",
      " [1631 1658]\n",
      " [1659 1694]\n",
      " [1695 1728]\n",
      " [1729 1820]\n",
      " [1821 1838]\n",
      " [1839 1853]\n",
      " [1854 1884]\n",
      " [1885 1926]\n",
      " [1927 1947]\n",
      " [1948 2004]\n",
      " [2005 2009]\n",
      " [2010 2019]\n",
      " [2020 2050]\n",
      " [2051 2091]\n",
      " [2092 2113]\n",
      " [2114 2154]\n",
      " [2155 2169]\n",
      " [2170 2195]\n",
      " [2196 2236]\n",
      " [2237 2277]\n",
      " [2278 2298]\n",
      " [2299 2414]\n",
      " [2415 2464]\n",
      " [2465 2500]\n",
      " [2501 2517]\n",
      " [2518 2546]\n",
      " [2547 2599]\n",
      " [2600 2641]\n",
      " [2642 2724]\n",
      " [2725 2763]\n",
      " [2764 2795]\n",
      " [2796 2831]\n",
      " [2832 2857]\n",
      " [2858 2877]\n",
      " [2878 2899]\n",
      " [2900 2938]\n",
      " [2939 2959]\n",
      " [2960 2982]\n",
      " [2983 2997]\n",
      " [2998 3019]\n",
      " [3020 3043]\n",
      " [3044 3064]\n",
      " [3065 3085]\n",
      " [3086 3106]\n",
      " [3107 3147]\n",
      " [3148 3162]\n",
      " [3163 3187]\n",
      " [3188 3209]\n",
      " [3210 3229]\n",
      " [3230 3313]\n",
      " [3314 3354]\n",
      " [3355 3395]\n",
      " [3396 3417]\n",
      " [3418 3438]\n",
      " [3439 3458]\n",
      " [3459 3510]\n",
      " [3511 3559]\n",
      " [3560 3603]\n",
      " [3604 3686]\n",
      " [3687 3707]\n",
      " [3708 3729]\n",
      " [3730 3750]\n",
      " [3751 3769]\n",
      " [3770 3790]\n",
      " [3791 3818]\n",
      " [3819 3888]\n",
      " [3889 3945]\n",
      " [3946 3988]\n",
      " [3989 4026]\n",
      " [4027 4076]\n",
      " [4077 4128]\n",
      " [4129 4235]\n",
      " [4236 4263]\n",
      " [4264 4291]\n",
      " [4292 4337]\n",
      " [4338 4402]\n",
      " [4403 4440]\n",
      " [4441 4484]\n",
      " [4485 4513]\n",
      " [4514 4546]\n",
      " [4547 4585]\n",
      " [4586 4601]\n",
      " [4602 4661]\n",
      " [4662 4744]\n",
      " [4745 4771]\n",
      " [4772 4806]\n",
      " [4807 4843]\n",
      " [4844 4913]\n",
      " [4914 4982]\n",
      " [4983 5030]\n",
      " [5031 5069]\n",
      " [5070 5125]\n",
      " [5126 5167]\n",
      " [5168 5194]\n",
      " [5195 5240]\n",
      " [5241 5280]\n",
      " [5281 5310]\n",
      " [5311 5357]\n",
      " [5358 5396]\n",
      " [5397 5436]\n",
      " [5437 5483]\n",
      " [5484 5508]\n",
      " [5509 5543]\n",
      " [5544 5559]\n",
      " [5560 5588]\n",
      " [5589 5616]\n",
      " [5617 5675]\n",
      " [5676 5727]\n",
      " [5728 5776]\n",
      " [5777 5810]\n",
      " [5811 5882]\n",
      " [5883 5910]\n",
      " [5911 6034]\n",
      " [6035 6063]\n",
      " [6064 6088]\n",
      " [6089 6218]\n",
      " [6219 6242]\n",
      " [6243 6285]\n",
      " [6286 6302]\n",
      " [6303 6327]\n",
      " [6328 6351]\n",
      " [6352 6401]\n",
      " [6402 6458]\n",
      " [6459 6493]\n",
      " [6494 6616]\n",
      " [6617 6639]\n",
      " [6640 6687]\n",
      " [6688 6737]\n",
      " [6738 6815]\n",
      " [6816 6883]\n",
      " [6884 6916]\n",
      " [6917 7004]\n",
      " [7005 7055]\n",
      " [7056 7099]\n",
      " [7100 7206]\n",
      " [7207 7257]\n",
      " [7258 7420]\n",
      " [7422 7663]\n",
      " [7664 7675]]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    # shape: batch dim x video frames x frame height x frame width x RGB (not BGR) channels\n",
    "    scenes = predict_video('../../Test_dataset/00112.mp4', model)\n",
    "    print(\"Detected scenes:\", scenes)\n",
    "    #visualize_detection('../../Dataset/00100.mp4', scenes,'./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc9f82cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 75\u001b[39m\n\u001b[32m     73\u001b[39m scenes_np = np.array(scenes)\n\u001b[32m     74\u001b[39m \u001b[38;5;28mprint\u001b[39m(os.path.exists(\u001b[33m\"\u001b[39m\u001b[33m00112.mp4\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m \u001b[43mvisualize_shots_scrollable\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m00112.mp4\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscenes_np\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 70\u001b[39m, in \u001b[36mvisualize_shots_scrollable\u001b[39m\u001b[34m(video_path, scenes_data)\u001b[39m\n\u001b[32m     67\u001b[39m     pair_frame.start_img_tk = start_img_tk\n\u001b[32m     68\u001b[39m     pair_frame.end_img_tk = end_img_tk\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m \u001b[43mroot\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmainloop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/tkinter/__init__.py:1485\u001b[39m, in \u001b[36mMisc.mainloop\u001b[39m\u001b[34m(self, n)\u001b[39m\n\u001b[32m   1483\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmainloop\u001b[39m(\u001b[38;5;28mself\u001b[39m, n=\u001b[32m0\u001b[39m):\n\u001b[32m   1484\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Call the mainloop of Tk.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1485\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmainloop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def extract_frame(video_path, frame_idx):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
    "    ret, frame = cap.read()\n",
    "    cap.release()\n",
    "    if not ret:\n",
    "        return None\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    return Image.fromarray(frame_rgb)\n",
    "\n",
    "def visualize_shots_scrollable(video_path, scenes_data):\n",
    "    if isinstance(scenes_data, torch.Tensor):\n",
    "        scenes_data = scenes_data.cpu().numpy()\n",
    "    elif isinstance(scenes_data, list):\n",
    "        scenes_data = np.array(scenes_data)\n",
    "\n",
    "    root = tk.Tk()\n",
    "    root.title(\"Shot Boundary Viewer\")\n",
    "    def on_closing():\n",
    "        root.quit()\n",
    "        root.destroy()\n",
    "\n",
    "    root.protocol(\"WM_DELETE_WINDOW\", on_closing)\n",
    "\n",
    "    main_frame = ttk.Frame(root)\n",
    "    main_frame.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "    canvas = tk.Canvas(main_frame)\n",
    "    scrollbar = ttk.Scrollbar(main_frame, orient=tk.VERTICAL, command=canvas.yview)\n",
    "    scrollable_frame = ttk.Frame(canvas)\n",
    "\n",
    "    scrollable_frame.bind(\n",
    "        \"<Configure>\",\n",
    "        lambda e: canvas.configure(\n",
    "            scrollregion=canvas.bbox(\"all\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "    canvas.create_window((0, 0), window=scrollable_frame, anchor=\"nw\")\n",
    "    canvas.configure(yscrollcommand=scrollbar.set)\n",
    "\n",
    "    canvas.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)\n",
    "    scrollbar.pack(side=tk.RIGHT, fill=tk.Y)\n",
    "\n",
    "    for idx, (start, end) in enumerate(scenes_data):\n",
    "        start_img = extract_frame(video_path, int(start))\n",
    "        end_img = extract_frame(video_path, int(end))\n",
    "\n",
    "        if start_img is None or end_img is None:\n",
    "            continue\n",
    "\n",
    "        start_img_tk = ImageTk.PhotoImage(start_img.resize((160, 90)))\n",
    "        end_img_tk = ImageTk.PhotoImage(end_img.resize((160, 90)))\n",
    "\n",
    "        pair_frame = ttk.Frame(scrollable_frame, padding=10)\n",
    "        pair_frame.pack(fill=tk.X)\n",
    "\n",
    "        ttk.Label(pair_frame, text=f\"Shot {idx+1}: [{start}-{end}]\").pack(anchor=\"w\")\n",
    "\n",
    "        images_frame = ttk.Frame(pair_frame)\n",
    "        images_frame.pack()\n",
    "\n",
    "        ttk.Label(images_frame, image=start_img_tk).pack(side=tk.LEFT, padx=5)\n",
    "        ttk.Label(images_frame, image=end_img_tk).pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        # Store reference to avoid garbage collection\n",
    "        pair_frame.start_img_tk = start_img_tk\n",
    "        pair_frame.end_img_tk = end_img_tk\n",
    "\n",
    "    root.mainloop()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    scenes_np = np.array(scenes)\n",
    "    print(os.path.exists(\"00112.mp4\"))\n",
    "    visualize_shots_scrollable(\"00112.mp4\", scenes_np)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VCA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
